<?xml version="1.0" encoding="UTF-8" ?><ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3"><Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0"><bitmap>media/images/box/root.png</bitmap><script language="4"><content><![CDATA[]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /><Timeline enable="0"><BehaviorLayer name="behavior_layer1"><BehaviorKeyframe name="keyframe1" index="1"><Diagram><Box name="Learn Place" id="1" localization="8" tooltip="This box contains a Python script that allows the robot to learn the coordinates of a new place and add it to the map. If the map is not empty, the robot needs to know its position with respect to the environment (the transformation matrix must be present in the memory), before the new place can be added." x="208" y="69"><bitmap>media/images/box/box-python-script.png</bitmap><script language="4"><content><![CDATA[sys.path.append("/data/home/nao/.local/share/PackageManager/apps/movement/libs/")
import qi
import sys
from naoqi import ALProxy
import os
import re
import json
import numpy as np

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.memory = ALProxy("ALMemory")
        self.motion = ALProxy("ALMotion")
        self.animated_speech = ALProxy("ALAnimatedSpeech")
        self.configuration = {"bodyLanguageMode": "contextual"}
        try:
            self.voice_speed = "\\RSPD=" + str(self.memory.getData("CAIR/voice_speed")) + "\\"
        except:
            self.voice_speed = "\\RSPD=80\\"
        self.place_key = -1
        self.asr_service = ALProxy("ALSpeechRecognition")
        self.tts = ALProxy("ALTextToSpeech")
        # asr needs to be paused before changing the language and setting the vocabulary
        self.asr_service.pause(True)
        # change the language to overcome vocabulary problem
        self.asr_service.setLanguage("Italian")
        self.asr_service.setLanguage("English")
        vocabulary = ["yes", "no"]
        self.asr_service.pause(True)
        self.asr_service.setVocabulary(vocabulary, False)

        self.sASR = ALProxy("ASR2")
        self.al = ALProxy("ALAutonomousLife")
        self.speech_reco_event = "Audio/RecognizedWords"

    def setAutonomousAbilities(self, blinking, background, awareness, listening, speaking):
        self.al.setAutonomousAbilityEnabled("AutonomousBlinking", blinking)
        self.al.setAutonomousAbilityEnabled("BackgroundMovement", background)
        self.al.setAutonomousAbilityEnabled("BasicAwareness", awareness)
        self.al.setAutonomousAbilityEnabled("ListeningMovement", listening)
        self.al.setAutonomousAbilityEnabled("SpeakingMovement", speaking)

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def get_places_from_map(self):
        with open("/data/home/nao/.local/share/PackageManager/apps/movement/map.txt", 'r') as f:
            lines = f.readlines()

        places = {}
        for line in lines:
            # Check that the line is not empty
            if line != '\n':
                place = line.split('_')[0]
                X = float(line.split('_')[1])
                Y = float(line.split('_')[2])
                Theta = float(line.split('_')[3])
                places[place] = (X, Y, Theta)
        result = json.dumps(places)
        self.logger.info("Map places: " + result)
        return places

    def onInput_onStart(self):

        try:
            where = str(self.memory.getData("CAIR/learn_place"))
            self.logger.info(where)
            where = where.strip()
            if where == "None":
                raise Exception("No data")
        # If there is no parameter, ask for it
        except:
            self.animated_speech.say(self.voice_speed + "Which place is this?", self.configuration)

            # Start speech recognition
            self.sASR.startReco("English", False, True)
            self.setAutonomousAbilities(True, True, True, True, True)

            start_time_silence = time.time() + 1800

            sentence = ""
            reco_speech = self.memory.getData(self.speech_reco_event)
            self.logger.info(str(reco_speech))
            stop = False

            while True:
                while not reco_speech:
                    if sentence and time.time() - start_time_silence > 0.1:
                        self.sASR.stopReco()
                        self.setAutonomousAbilities(False, True, True, True, True)
                        stop = True
                        break
                    reco_speech = self.memory.getData(self.speech_reco_event)
                    print reco_speech
                sys.stdout.flush()
                if stop:
                    break
                if sentence == "":
                    sep = ""
                else:
                    sep = " "

                if reco_speech:
                    sentence = sentence + sep + reco_speech[0][0]
                start_time_silence = time.time()
                self.memory.insertData(self.speech_reco_event, [])
                reco_speech = self.memory.getData(self.speech_reco_event)

                exit_keywords = ["exit", "quit", "stop"]
                if sentence.lower() in exit_keywords:
                    self.onInput_onStop()

            self.logger.info(str(sentence))
            self.memory.insertData(self.speech_reco_event, [])
            self.memory.insertData("CAIR/learn_place", str(sentence))
            where = str(self.memory.getData("CAIR/learn_place"))

        # Get the name of place the user wants to add from the memory
        places = self.get_places_from_map()

        # Get the position of the robot wrt its odometry
        odometry = self.motion.getRobotPosition(True)
        Px_r = round(odometry[0], 2)
        Py_r = round(odometry[1], 2)
        Ptheta_r = round(odometry[2], 2)
        P_r = [Px_r, Py_r, 1.0]

        # Check if the transformation matrix of the robot wrt the environment exists
        try:
            # If the transformation exists, the position should be computed wrt the enviromnent
            transformation_matrix = self.memory.getData("CAIR/transformation_matrix")
            theta = self.memory.getData("CAIR/theta")
            Pr_w = np.dot(transformation_matrix, np.array([P_r]).T)
            Pr_w = [round(Pr_w[0], 2), round(Pr_w[1], 2), 1.0, round(Ptheta_r + theta, 2)]
            self.logger.info("Position of the robot wrt the world:" + str(Pr_w))

            for k in places.keys():
                if str(where) == k:
                    self.place_key = k
                    self.logger.info("Already existing place: " + str(where))

            # If the place already exists in the map
            if self.place_key != -1:
                self.animated_speech.say(self.voice_speed + "This place is already present in the map. Do you want to overwrite the location of the " + str(where) +  "?", self.configuration)
                self.asr_service.pause(False)
                self.asr_service.subscribe("Test_ASR")
                time.sleep(5)
                answer = self.memory.getData("WordRecognized")[0]
                self.asr_service.unsubscribe("Test_ASR")
                self.logger.info(answer)

                if answer == "yes":
                    with open("/data/home/nao/.local/share/PackageManager/apps/movement/map.txt", 'r') as f:
                        lines = f.readlines()
                    with open("/data/home/nao/.local/share/PackageManager/apps/movement/map.txt", 'w') as f:
                        for line in lines:
                            if line != '\n':
                                if line.split('_')[0] != self.place_key:
                                    f.write(line)
                        f.write('\n' + where + "_" + str(Pr_w[0]) + '_' + str(Pr_w[1]) + '_' + str(Pr_w[3]))
                    self.animated_speech.say(self.voice_speed + "Ok. I updated the position of the " + str(where) +  ".", self.configuration)
                else:
                    self.animated_speech.say(self.voice_speed + "Ok. I will not update the position of the" + str(where) +  ".", self.configuration)

            # If the place does already not exist in the map
            else:
                with open("/data/home/nao/.local/share/PackageManager/apps/movement/map.txt", 'a') as f:
                    f.write('\n' + where + "_" + str(Pr_w[0]) + '_' + str(Pr_w[1]) + '_' + str(Pr_w[3]))

                self.animated_speech.say(self.voice_speed + "Now I now that this place is the " + str(where) +  ".", self.configuration)

        # If the transformation matrix does not exist in the memory, it means the robot does not know its position
        except:
            # Check if the file is empty:
            if os.stat("/data/home/nao/.local/share/PackageManager/apps/movement/map.txt").st_size == 0:
                # If it's empty, store the current position with respect to the robot's odometry
                with open("/data/home/nao/.local/share/PackageManager/apps/movement/map.txt", 'a') as f:
                    f.write('\n' + where + "_" + str(Px_r) + '_' + str(Py_r) + '_' + str(Ptheta_r))

                theta = 0
                transformation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],
                                              [np.sin(theta), np.cos(theta), 0],
                                              [0, 0, 1]])
                self.logger.info("Transformation matrix:" + str(transformation_matrix))
                self.memory.insertData("CAIR/transformation_matrix", transformation_matrix.tolist())
                self.memory.insertData("CAIR/theta", theta)

                self.animated_speech.say(self.voice_speed + "This is the first place of the map. Now I know that this is the " + str(where) +  ".", self.configuration)

            # If the file is not empty, but the robot does not know the transformation, it can't learn the new place
            else:
                self.animated_speech.say(self.voice_speed + "The map is not empty, but I don't know where I am. Please, bring me to a known position before telling me to add a new place.", self.configuration)

        self.onInput_onStop()


    def onInput_onStop(self):
        self.onUnload() #it is recommended to reuse the clean-up as the box is stopped
        self.onStopped() #activate the output of the box]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /></Box><Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" /><Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="4" /></Diagram></BehaviorKeyframe></BehaviorLayer></Timeline></Box></ChoregrapheProject>